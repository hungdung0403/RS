{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBwithW2V.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORT THƯ VIỆN VÀ LOAD DATA"
      ],
      "metadata": {
        "id": "VkE51wiWDMRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjwCfpegXmKh",
        "outputId": "638650cc-a056-4a5c-8b1a-cab4d8c35015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.2)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.1.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Collecting underthesea-core==0.0.4_alpha.10\n",
            "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n",
            "\u001b[K     |████████████████████████████████| 581 kB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.4 underthesea-core-0.0.4a10 unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.4.0\n",
            "  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (5.2.1)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.4.0-cp37-cp37m-linux_x86_64.whl size=23316742 sha256=327aa5d23ac5d54ad7f51b2f350c8ed445c96a1f55dcde28c117f83f330d9e20\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/a4/46/4e18f7d25915b16e0e790a5362e455aba6cadc486994806c05\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.4.0\n",
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "!pip install underthesea\n",
        "!pip install openpyxl ##engine\n",
        "!pip install gensim==3.4.0\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import class_weight as cw\n",
        "from sklearn import utils\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from underthesea import word_tokenize\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "import multiprocessing\n",
        "# Word2vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "df = pd.read_csv('/content/drive/MyDrive/clab/full.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TIỀN XỬ LÝ DỮ LIỆU"
      ],
      "metadata": {
        "id": "6YdQsKUuDVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_k_dau(df):\n",
        "    alpha_vn =\"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸĐ\"\n",
        "    index=[]\n",
        "    for i,text in enumerate(df.comment.astype(str)):\n",
        "        words = text.split(' ')\n",
        "        k_dau = []\n",
        "        if len(words) >=5:\n",
        "            for word in words:\n",
        "                for char in alpha_vn:\n",
        "                    if char in word:\n",
        "                        k_dau.append(word)  \n",
        "            if len(k_dau)==0:\n",
        "                index.append(i)    \n",
        "    df=df.drop(index,axis=0)\n",
        "    return df\n",
        "\n",
        "dic = pd.read_excel('/content/dictionary_new.xlsx','Sheet1')\n",
        "fullcom = dic.set_index('Short').T.to_dict('list')# biến đổi câu có từ viết tắt thành câu hoàn chỉnh\n",
        "def slang(text) : \n",
        "    result = []\n",
        "    for word in text.split() : \n",
        "        try :\n",
        "            word = fullcom[word][0]\n",
        "            result.append(word)\n",
        "        except :\n",
        "            result.append(word)\n",
        "\n",
        "    sentence=' '.join(word for word in result)\n",
        "    return sentence\n",
        "# tạo stopword\n",
        "with open('/content/vietnamese_stopword_2.txt') as f:\n",
        "    data = f.read()\n",
        "new_stopword = [ ]\n",
        "stopword_list = [line for line in data.split('\\n') if line != '']\n",
        "stopword_list=stopword_list + new_stopword\n",
        "stop_word= set(stopword_list)\n",
        "stop_words=[]\n",
        "for word in stop_word:\n",
        "    stop_words.append(word.replace(\" \",\"_\"))\n",
        "# tạo elongated: vuiiii -> vui\n",
        "import re\n",
        "from itertools import groupby\n",
        "\n",
        "# Xóa emoji\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "#Loại bỏ spam : \n",
        "def spam(text) :\n",
        "    sentence = []\n",
        "    for word in text.split() :\n",
        "        if len(word) < 6 :\n",
        "           sentence.append(word) \n",
        "        else :\n",
        "            word = \" \"    \n",
        "    sentence=' '.join(word for word in sentence)\n",
        "    return sentence\n",
        "\n",
        "# biến đổi câu có từ viết tắt thành câu hoàn chỉnh\n",
        "def slang(text) : \n",
        "    result = []\n",
        "    for word in text.split() : \n",
        "        try :\n",
        "            word = fullcom[word][0]\n",
        "            result.append(word)\n",
        "        except :\n",
        "            result.append(word)\n",
        "\n",
        "    sentence=' '.join(word for word in result)\n",
        "    return sentence\n",
        "# dùng thư viện underthesea để nối từ\n",
        "def convert_word_tokenize(text):\n",
        "    return word_tokenize(text,format='text')\n",
        "\n",
        "def elongated_remove(text):\n",
        "    return ''.join(c for c, _ in groupby(text))\n",
        "\n",
        "# tạo negation: ví dụ câu: Tôi không thích đi học -> Tôi không_thích đi học\n",
        "def negation_handling(text):\n",
        "    negation = False\n",
        "    result = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        stripped = word.strip().lower()\n",
        "        negated = \"không_\" + stripped if negation else stripped\n",
        "        if negation == True:\n",
        "            negation = not negation\n",
        "        result.append(negated)\n",
        "        if any(neg == word for neg in [\"không\",\"chưa\",\"chẳng\",\"chả\",\"đừng\"\n",
        "                                       \"Không\",\"Chưa\",\"Chả\",\"Chẳng\",\"Đừng\"]):\n",
        "            negation = not negation\n",
        "    for word in result:\n",
        "        if word in [\"không\",\"chưa\",\"chẳng\",\"chả\",\"đừng\"\n",
        "                    \"Không\",\"Chưa\",\"Chả\",\"Chẳng\",\"Đừng\"]:\n",
        "            result.remove(word)\n",
        "    result = ' '.join(result)\n",
        "    return result\n",
        "\n",
        "# tạo intensification: ví dụ câu: Tôi rất thích đi học -> Tôi rất_thích đi học\n",
        "def intensification_handling(text):\n",
        "    negation = False\n",
        "    result = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        stripped = word.strip().lower()\n",
        "        negated = \"rất_\" + stripped if negation else stripped\n",
        "        if negation == True:\n",
        "            negation = not negation\n",
        "        result.append(negated)\n",
        "        if any(neg == word for neg in [\"rất\",\"khá\",\"hơi\",\"quá\",\"toàn\",\n",
        "                                      \"Rất\",\"Khá\",\"Hơi\",\"Quá\",\"Toàn\"]):\n",
        "            negation = not negation\n",
        "    for word in result:\n",
        "        if word in ['rất','hơi','khá','quá','toàn',\n",
        "                   \"Rất\",\"Khá\",\"Hơi\",\"Quá\",\"Toàn\"]:\n",
        "            result.remove(word)\n",
        "    result = ' '.join(result)\n",
        "    return result\n",
        "  # Xóa code html\n",
        "def remove_html(txt):\n",
        "    return re.sub(r'<[^>]*>', '', txt)\n",
        "\n",
        "# xóa link\n",
        "def remove_url(document):\n",
        "    document = re.sub(r\"(http\\S+)|(www\\S+)\", '', document)\n",
        "    return document\n",
        "\n",
        "# xóa tag user\n",
        "def remove_tag_user(document):\n",
        "    document = re.sub(r\"(@\\w{1,15})\", '', document)\n",
        "    return document\n",
        "\n",
        "# xóa hashtags\n",
        "def remove_hashtags(document):\n",
        "    document = re.sub(\"#(\\w{1,})\", '', document)\n",
        "    return document\n",
        "\n",
        "# Chuẩn hóa unicode\n",
        "import regex as re\n",
        "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
        "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
        "def loaddicchar():\n",
        "    dic = {}\n",
        "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
        "        '|')\n",
        "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
        "        '|')\n",
        "    for i in range(len(char1252)):\n",
        "        dic[char1252[i]] = charutf8[i]\n",
        "    return dic\n",
        "dicchar = loaddicchar()\n",
        "def convert_unicode(txt):\n",
        "    return re.sub(\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
        "        lambda x: dicchar[x.group()], txt)\n",
        "\n",
        "# Chuẩn hóa dấu tiếng việt\n",
        "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "nguyen_am_to_ids = {}\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9: \n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5: \n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  \n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            return ''.join(chars)\n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "        else:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    return ''.join(chars)\n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Chuyển 100k thành giá tiền\n",
        "def money(text):\n",
        "    text = re.sub('(\\d+k)|(\\d+ k)|(\\d+đồng)|(\\d+ đồng)|(\\d+ngàn)|(\\d+ ngàn)|(\\d+nghìn)|(\\d+ nghìn)', 'giá_tiền', text)\n",
        "    return text# Xóa code html\n",
        "\n",
        "def remove_stopword(text):\n",
        "    sentence=[]\n",
        "    for word in text.split():\n",
        "        if word not in stop_words:\n",
        "            sentence.append(word)\n",
        "    sentence= ' '.join(word for word in sentence)\n",
        "    return sentence\n",
        "# xóa số trong câu\n",
        "def clean_number_object(string: str, punctuations=r'''!+()-[]{};:'\"\\,<>./?@#$%^&~1234657890''') -> str:\n",
        "    # Xóa số\n",
        "    for x in string.lower(): \n",
        "        if x in punctuations: \n",
        "            string = string.replace(x, \"\") \n",
        "    return string\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLuQ83fwfTpX",
        "outputId": "924d7e36-fbb8-4a2a-d601-0b495c045eca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(data_comment):\n",
        "    new_comment=[]\n",
        "    for text in data_comment:\n",
        "        text = remove_emojis(text)\n",
        "        text = remove_html(text)\n",
        "        text = remove_url(text)\n",
        "        text = remove_tag_user(text)\n",
        "        text = remove_hashtags(text)\n",
        "        text = elongated_remove(text)\n",
        "        text = chuan_hoa_dau_cau_tieng_viet(text)\n",
        "        text = spam(text)\n",
        "        text = money(text)\n",
        "        text = slang(text)\n",
        "        text = convert_unicode(text)\n",
        "        text = clean_number_object(text)\n",
        "        text = intensification_handling(text)\n",
        "        text = negation_handling(text)\n",
        "        text = convert_word_tokenize(text)\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        text = remove_stopword(text)\n",
        "        new_comment.append(text)\n",
        "    return new_comment"
      ],
      "metadata": {
        "id": "F8whHjsNfmBs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop_duplicates(subset='Description_Prod')\n",
        "df1 = df1.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'Description_Product', 'Index'])\n",
        "df1 = df1.dropna(subset=[\"User_id\", \"User_Rating\", \"Prod_id\"])\n",
        "df1 = df1.reset_index()\n",
        "df1 = df1.drop(columns='index')\n",
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2_4PUeEZwWz",
        "outputId": "9a614e74-0fb6-485f-cbdf-a73e088a96da"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 598 entries, 0 to 597\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Shop_id           598 non-null    int64  \n",
            " 1   Shop_Name         598 non-null    object \n",
            " 2   Prod_id           598 non-null    int64  \n",
            " 3   Prod_Name         598 non-null    object \n",
            " 4   Description_Prod  598 non-null    object \n",
            " 5   Price             598 non-null    float64\n",
            " 6   Average_Rating    598 non-null    float64\n",
            " 7   Total_Comments    598 non-null    int64  \n",
            " 8   User_Rating       598 non-null    float64\n",
            " 9   User_id           598 non-null    float64\n",
            " 10  User_Review       595 non-null    object \n",
            " 11  URL               598 non-null    object \n",
            "dtypes: float64(4), int64(3), object(5)\n",
            "memory usage: 56.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Description_Prod'] = pre_process(df1['Description_Prod'].astype(str))"
      ],
      "metadata": {
        "id": "hWIn81wPfuTn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TFIDF"
      ],
      "metadata": {
        "id": "zmX4cBfn_WVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_name_food_(index):\n",
        "    return df1['Prod_Name'].iloc[index]"
      ],
      "metadata": {
        "id": "OFcZ-HsuEszL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "def recommendation_system_food_using_TFTDF_(food_id, number):\n",
        "  # food index mapping\n",
        "  mapping1 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "  id1 = mapping1[food_id]\n",
        "  #print('Id1:',id1)\n",
        "  #print('List mapping of product name:\\n',mapping)\n",
        "  product1 = mapping1.index[id1]\n",
        "  #print(product1)\n",
        "\n",
        "  demo_id1 = mapping1.get(key = product1)\n",
        "  #print('Demo_id1:',demo_id1)\n",
        "  mapping2 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "  id2 = mapping2.get(key = product1)\n",
        "  #print('Id2:',id2)\n",
        "  product2 = mapping2.index[id2]\n",
        "  #print(product2)\n",
        "\n",
        "\n",
        "  # TF-TDF\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_vectorizer = vectorizer.fit(df1['Description_Prod'])\n",
        "  #print(tfidf_vectorizer)\n",
        "\n",
        "  overview_matrix = tfidf_vectorizer.transform(df1['Description_Prod'])\n",
        "  #print(overview_matrix)\n",
        "  #print('Overview_matrix shape:',overview_matrix.shape)\n",
        "\n",
        "  similarity_matrix = linear_kernel(overview_matrix, overview_matrix)\n",
        "  #print('Similarity_matrix:\\n',similarity_matrix)\n",
        "  #print('Similarity_matrix shape:',similarity_matrix.shape)\n",
        "\n",
        "  # Recommendation\n",
        "  print('Product name users need to recommend to them:\\n', product2)\n",
        "  similarity_score = list(enumerate(similarity_matrix[id2]))\n",
        "  global foodname\n",
        "  foodname = product2\n",
        "\n",
        "  similarity_score = sorted(similarity_score, key = lambda x: x[1], reverse = True)\n",
        "  similarity_score = similarity_score[1:21]\n",
        "  recommendation = [(get_name_food_(id) , score) for id, score in similarity_score]\n",
        "\n",
        "  # Xuất ra danh sách top 10 sản phẩm được khuyến nghị cho người dùng với một sản phẩm chỉ định dưới dạng bảng\n",
        "  recommendation_df = pd.DataFrame(recommendation, columns=['Prod_Name','Cosine_similarity'])\n",
        "  recommendation_df = pd.merge(df1, recommendation_df, on=\"Prod_Name\", how=\"inner\")\n",
        "  recommendation_df = recommendation_df.sort_values(by=['Cosine_similarity'],ascending=False)\n",
        "  recommendation_df = recommendation_df.head(number)\n",
        "  print(recommendation_df['Prod_Name'])\n",
        "\n",
        "  return recommendation_df"
      ],
      "metadata": {
        "id": "JfYu6w2k_TW9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_system_food_using_TFTDF_(200, 5)"
      ],
      "metadata": {
        "id": "rfh6cQMaATbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "17659abb-3752-42a0-f57f-4a9093d2b8e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product name users need to recommend to them:\n",
            " Hủ 200gr ruốc xấy ngon số 1 TÂY NINH dùng chung bánh \n",
            "18                           500g Ruốc Sấy Tây Ninh Giò\n",
            "13    {Ruốc gà thịt tươi 💯}Hạnh Gà/ Ruốc Gà - chà bô...\n",
            "16                 Đồ Ăn Nhanh Ruốc Cá Chép,Chà Bông Cá\n",
            "19          100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu\n",
            "11                     Hủ 300G Ruốc Sấy Hành Phi Trọng \n",
            "Name: Prod_Name, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Shop_id                  Shop_Name      Prod_id  \\\n",
              "18  237204869          dacsanphanrangso1   9207719667   \n",
              "13   50421059                    Hạnh Gà   2767491558   \n",
              "16  667449329         THẢO MỘC ĐỒNG XANH  17103008545   \n",
              "19   63406509  Đặc Sản Đà Nẵng Chính Gốc  12557561629   \n",
              "11   17447969     BÁNH TRÁNG TRỌNG NGHĨA    247272852   \n",
              "\n",
              "                                            Prod_Name  \\\n",
              "18                         500g Ruốc Sấy Tây Ninh Giò   \n",
              "13  {Ruốc gà thịt tươi 💯}Hạnh Gà/ Ruốc Gà - chà bô...   \n",
              "16               Đồ Ăn Nhanh Ruốc Cá Chép,Chà Bông Cá   \n",
              "19        100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu   \n",
              "11                   Hủ 300G Ruốc Sấy Hành Phi Trọng    \n",
              "\n",
              "                                     Description_Prod         Price  \\\n",
              "18  ruốc sấy khô liệu ruốc biển tươi sạch sấy khô ...   59420.60320   \n",
              "13  ruốc gà giã bằng gà tươi nên sợi ruốc ăn thơm ...  160283.04651   \n",
              "16  thông_tin sản_phẩm ruốc cá chép ruốc hợp_tác_x...  327683.30011   \n",
              "19  tôm ruốc tôm đà nẵng siêu ngon đặc_điểm sợi ru...   71966.25222   \n",
              "11  ruốc sấy hành phi thành_phần ruốc hành phi_hàn...   95462.18337   \n",
              "\n",
              "    Average_Rating  Total_Comments  User_Rating      User_id  \\\n",
              "18        2.311383              29          5.0   64154689.0   \n",
              "13        2.087949              26          5.0   38479513.0   \n",
              "16        2.739733               2          5.0  471091541.0   \n",
              "19        5.998826               2          5.0  257376075.0   \n",
              "11        4.902445              21          4.0   44504253.0   \n",
              "\n",
              "                                          User_Review  \\\n",
              "18  Video hình ảnh mang tính chất nhận xu ạ. \\nSho...   \n",
              "13  Ruốc ngon lắm, ai ăn nhạt thì vừa còn ai ai ăn...   \n",
              "16  Giao hàng nhanh, ruốc thơm, ngon. Nhưng thi th...   \n",
              "19  Đậm vị quá ngon chất lượng giá hợp lý ship hàn...   \n",
              "11  Mình ăn vào lại thấy có vị nhẫn ko biết nguyên...   \n",
              "\n",
              "                                                  URL  Cosine_similarity  \n",
              "18  https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...           0.465455  \n",
              "13  https://shopee.vn/-Ru%E1%BB%91c-g%C3%A0-th%E1%...           0.427757  \n",
              "16  https://shopee.vn/%C4%90%E1%BB%93-%C4%82n-Nhan...           0.397616  \n",
              "19  https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...           0.367723  \n",
              "11  https://shopee.vn/H%E1%BB%A7-300G-Ru%E1%BB%91c...           0.329758  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Shop_id</th>\n",
              "      <th>Shop_Name</th>\n",
              "      <th>Prod_id</th>\n",
              "      <th>Prod_Name</th>\n",
              "      <th>Description_Prod</th>\n",
              "      <th>Price</th>\n",
              "      <th>Average_Rating</th>\n",
              "      <th>Total_Comments</th>\n",
              "      <th>User_Rating</th>\n",
              "      <th>User_id</th>\n",
              "      <th>User_Review</th>\n",
              "      <th>URL</th>\n",
              "      <th>Cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>237204869</td>\n",
              "      <td>dacsanphanrangso1</td>\n",
              "      <td>9207719667</td>\n",
              "      <td>500g Ruốc Sấy Tây Ninh Giò</td>\n",
              "      <td>ruốc sấy khô liệu ruốc biển tươi sạch sấy khô ...</td>\n",
              "      <td>59420.60320</td>\n",
              "      <td>2.311383</td>\n",
              "      <td>29</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64154689.0</td>\n",
              "      <td>Video hình ảnh mang tính chất nhận xu ạ. \\nSho...</td>\n",
              "      <td>https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...</td>\n",
              "      <td>0.465455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>50421059</td>\n",
              "      <td>Hạnh Gà</td>\n",
              "      <td>2767491558</td>\n",
              "      <td>{Ruốc gà thịt tươi 💯}Hạnh Gà/ Ruốc Gà - chà bô...</td>\n",
              "      <td>ruốc gà giã bằng gà tươi nên sợi ruốc ăn thơm ...</td>\n",
              "      <td>160283.04651</td>\n",
              "      <td>2.087949</td>\n",
              "      <td>26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>38479513.0</td>\n",
              "      <td>Ruốc ngon lắm, ai ăn nhạt thì vừa còn ai ai ăn...</td>\n",
              "      <td>https://shopee.vn/-Ru%E1%BB%91c-g%C3%A0-th%E1%...</td>\n",
              "      <td>0.427757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>667449329</td>\n",
              "      <td>THẢO MỘC ĐỒNG XANH</td>\n",
              "      <td>17103008545</td>\n",
              "      <td>Đồ Ăn Nhanh Ruốc Cá Chép,Chà Bông Cá</td>\n",
              "      <td>thông_tin sản_phẩm ruốc cá chép ruốc hợp_tác_x...</td>\n",
              "      <td>327683.30011</td>\n",
              "      <td>2.739733</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>471091541.0</td>\n",
              "      <td>Giao hàng nhanh, ruốc thơm, ngon. Nhưng thi th...</td>\n",
              "      <td>https://shopee.vn/%C4%90%E1%BB%93-%C4%82n-Nhan...</td>\n",
              "      <td>0.397616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63406509</td>\n",
              "      <td>Đặc Sản Đà Nẵng Chính Gốc</td>\n",
              "      <td>12557561629</td>\n",
              "      <td>100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu</td>\n",
              "      <td>tôm ruốc tôm đà nẵng siêu ngon đặc_điểm sợi ru...</td>\n",
              "      <td>71966.25222</td>\n",
              "      <td>5.998826</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>257376075.0</td>\n",
              "      <td>Đậm vị quá ngon chất lượng giá hợp lý ship hàn...</td>\n",
              "      <td>https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...</td>\n",
              "      <td>0.367723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>17447969</td>\n",
              "      <td>BÁNH TRÁNG TRỌNG NGHĨA</td>\n",
              "      <td>247272852</td>\n",
              "      <td>Hủ 300G Ruốc Sấy Hành Phi Trọng</td>\n",
              "      <td>ruốc sấy hành phi thành_phần ruốc hành phi_hàn...</td>\n",
              "      <td>95462.18337</td>\n",
              "      <td>4.902445</td>\n",
              "      <td>21</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44504253.0</td>\n",
              "      <td>Mình ăn vào lại thấy có vị nhẫn ko biết nguyên...</td>\n",
              "      <td>https://shopee.vn/H%E1%BB%A7-300G-Ru%E1%BB%91c...</td>\n",
              "      <td>0.329758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WORD2VEC"
      ],
      "metadata": {
        "id": "MvwBpa9RENZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cores=multiprocessing.cpu_count()\n",
        "\n",
        "# model dùng Bag of word\n",
        "SEED = 455 # random\n",
        "W2V_SIZE = 400\n",
        "W2V_WINDOW = 9 # max distance bt the current and predicted\n",
        "W2V_EPOCH = 35 \n",
        "W2V_MIN_COUNT = 6 # Ignore word frequence < n\n",
        "\n",
        "w2v_model = Word2Vec(   seed=SEED, \n",
        "                        size=W2V_SIZE,\n",
        "                        window=W2V_WINDOW,\n",
        "                        min_count=W2V_MIN_COUNT,\n",
        "                        workers=cores\n",
        "                        )"
      ],
      "metadata": {
        "id": "LtT2-FmPX0MU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [_text.split() for _text in df1['Description_Prod'].astype(str)]"
      ],
      "metadata": {
        "id": "l5doahtKYuzQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "w2v_model.build_vocab(tqdm(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IABge7SAdsMA",
        "outputId": "77ead24d-c330-4d46-e45d-425e9738dfd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 598/598 [00:00<00:00, 34281.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohq3h6coYxKd",
        "outputId": "05d51fb7-b0f5-46d6-8cf1-8489e5c4de9e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1787283, 2356165)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.most_similar('ngon',topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RctazM9Y0rF",
        "outputId": "c539c9d4-f453-44b4-c523-0d3eceed3b7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dai', 0.7435066103935242),\n",
              " ('bạch_tuộc', 0.6610574722290039),\n",
              " ('thơm', 0.6519355177879333),\n",
              " ('đậm_đà', 0.6159470081329346),\n",
              " ('hương_vị', 0.6060012578964233),\n",
              " ('hấp_dẫn', 0.6024566292762756),\n",
              " ('đặc_trưng', 0.5924603939056396),\n",
              " ('râu', 0.5866954326629639),\n",
              " ('không_lẫn', 0.5854678153991699),\n",
              " ('mùi', 0.5647065043449402)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.init_sims(replace=True)\n",
        "print(w2v_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxYhrvNhhQJL",
        "outputId": "b592a221-199b-4c92-e6ba-cd01bfedfa2d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=1599, size=400, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectors(df1):\n",
        "    \n",
        "    # Creating a list for storing the vectors ('Description' into vectors)\n",
        "    global word_embeddings\n",
        "    word_embeddings = []\n",
        "\n",
        "    # Reading the each 'Description'\n",
        "    for line in df1['Description_Prod']:\n",
        "        avgword2vec = None\n",
        "        count = 0\n",
        "        for word in line.split():\n",
        "            if word in w2v_model.wv.vocab:\n",
        "                count += 1\n",
        "                if avgword2vec is None:\n",
        "                    avgword2vec = w2v_model[word]\n",
        "                else:\n",
        "                    avgword2vec = avgword2vec + w2v_model[word]\n",
        "                \n",
        "        if avgword2vec is not None:\n",
        "            avgword2vec = avgword2vec / count\n",
        "            word_embeddings.append(avgword2vec)"
      ],
      "metadata": {
        "id": "qX7F0OCvhZXM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "# Recommending the Top 10 similar food\n",
        "def recommendation_system_food_using_W2v_(prod_id, number):\n",
        "\n",
        "    # food index mapping\n",
        "    mapping1 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "    id1 = mapping1[prod_id]\n",
        "    #print('List mapping of product name:\\n',mapping)\n",
        "    product1 = mapping1.index[id1]\n",
        "\n",
        "    demo_id1 = mapping1.get(key = product1)\n",
        "    mapping2 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "    id2 = mapping2.get(key = product1)\n",
        "    product2 = mapping2.index[id2]\n",
        "  \n",
        "    global foodname\n",
        "    foodname = product2\n",
        "    # Calling the function vectors\n",
        "    vectors(df1)\n",
        "    # Finding cosine similarity for the vectors\n",
        "    similarity_matrix = cosine_similarity(word_embeddings, word_embeddings)\n",
        "    #similarity_matrix = linear_kernel(word_embeddings, word_embeddings)\n",
        "\n",
        "\n",
        "    # Recommendation\n",
        "    print('Product name users need to recommend to them:\\n', product2)\n",
        "    similarity_score = list(enumerate(similarity_matrix[id2]))\n",
        "    similarity_score = sorted(similarity_score, key = lambda x: x[1], reverse = True)\n",
        "    similarity_score = similarity_score[1:21]\n",
        "    recommendation = [(get_name_food_(id) , score) for id, score in similarity_score]\n",
        "    # Xuất ra danh sách top 10 sản phẩm được khuyến nghị cho người dùng với một sản phẩm chỉ định dưới dạng bảng\n",
        "    recommendation_df = pd.DataFrame(recommendation, columns=['Prod_Name','Cosine_similarity'])\n",
        "    recommendation_df = pd.merge(df1, recommendation_df, on=\"Prod_Name\", how=\"inner\")\n",
        "    recommendation_df = recommendation_df.sort_values(by=['Cosine_similarity'],ascending=False)\n",
        "    recommendation_df = recommendation_df.head(number)\n",
        "    print(recommendation_df['Prod_Name'])\n",
        "    return recommendation_df\n"
      ],
      "metadata": {
        "id": "XNXzy-Fwhh5O"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_system_food_using_W2v_(200, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "Ag8bpWji68MS",
        "outputId": "69e01102-13ba-4fb8-8ac1-f864be71e9cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product name users need to recommend to them:\n",
            " Hủ 200gr ruốc xấy ngon số 1 TÂY NINH dùng chung bánh \n",
            "13                           500g Ruốc Sấy Tây Ninh Giò\n",
            "16                                   Quả dâu tây sấy dẻ\n",
            "8                  100GR Bò khô xé sợi thơm ngon hàng l\n",
            "18          100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu\n",
            "11    [HÀ NỘI] Xúc Xích Sụn Gà Cay Ăn Liền 1 gói 4 v...\n",
            "Name: Prod_Name, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Shop_id                       Shop_Name      Prod_id  \\\n",
              "13  237204869               dacsanphanrangso1   9207719667   \n",
              "16   42004863                     huyenpi.kul  10477233552   \n",
              "8    43086726                     TLFood Shop   5806774572   \n",
              "18   63406509       Đặc Sản Đà Nẵng Chính Gốc  12557561629   \n",
              "11    2770707  Demacia Station - 39 Thụy Khuê   9539017473   \n",
              "\n",
              "                                            Prod_Name  \\\n",
              "13                         500g Ruốc Sấy Tây Ninh Giò   \n",
              "16                                 Quả dâu tây sấy dẻ   \n",
              "8                100GR Bò khô xé sợi thơm ngon hàng l   \n",
              "18        100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu   \n",
              "11  [HÀ NỘI] Xúc Xích Sụn Gà Cay Ăn Liền 1 gói 4 v...   \n",
              "\n",
              "                                     Description_Prod        Price  \\\n",
              "13  ruốc sấy khô liệu ruốc biển tươi sạch sấy khô ...  59420.60320   \n",
              "16  dâu_tây sấy dẻo đặc_sản cao_cấp dai dai mềm hư...  29825.88724   \n",
              "8   gr bò khô sợi heo giả bò món nhậu lý_tưởng đấn...  15134.89551   \n",
              "18  tôm ruốc tôm đà nẵng siêu ngon đặc_điểm sợi ru...  71966.25222   \n",
              "11  xúc_xích sụn non mới ngon lạ_miệng dai dai cắn...   9262.24843   \n",
              "\n",
              "    Average_Rating  Total_Comments  User_Rating      User_id  \\\n",
              "13        2.311383              29          5.0   64154689.0   \n",
              "16        2.301471              20          5.0  377287160.0   \n",
              "8         1.939551            2675          5.0  772005828.0   \n",
              "18        5.998826               2          5.0  257376075.0   \n",
              "11        0.588511               2          5.0  404031556.0   \n",
              "\n",
              "                                          User_Review  \\\n",
              "13  Video hình ảnh mang tính chất nhận xu ạ. \\nSho...   \n",
              "16  Jsjsnsjdjkd hình ảnh minh họa ,mang tc nhận xu...   \n",
              "8   Hương vị:nzndjdjdkd như cục đất\\n\\nĐnndnkkwlwk...   \n",
              "18  Đậm vị quá ngon chất lượng giá hợp lý ship hàn...   \n",
              "11  Sản phảmmmmm\\nM\\nM\\nMm\\nMm\\nMok\\nOkkkkkkkkkkkk...   \n",
              "\n",
              "                                                  URL  Cosine_similarity  \n",
              "13  https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...           0.895438  \n",
              "16  https://shopee.vn/Qu%E1%BA%A3-d%C3%A2u-t%C3%A2...           0.838509  \n",
              "8   https://shopee.vn/100GR-B%C3%B2-kh%C3%B4-x%C3%...           0.826895  \n",
              "18  https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...           0.823328  \n",
              "11  https://shopee.vn/-H%C3%80-N%E1%BB%98I-X%C3%BA...           0.819496  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29020bef-672d-4cd5-a09a-c8c0f13919a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Shop_id</th>\n",
              "      <th>Shop_Name</th>\n",
              "      <th>Prod_id</th>\n",
              "      <th>Prod_Name</th>\n",
              "      <th>Description_Prod</th>\n",
              "      <th>Price</th>\n",
              "      <th>Average_Rating</th>\n",
              "      <th>Total_Comments</th>\n",
              "      <th>User_Rating</th>\n",
              "      <th>User_id</th>\n",
              "      <th>User_Review</th>\n",
              "      <th>URL</th>\n",
              "      <th>Cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>237204869</td>\n",
              "      <td>dacsanphanrangso1</td>\n",
              "      <td>9207719667</td>\n",
              "      <td>500g Ruốc Sấy Tây Ninh Giò</td>\n",
              "      <td>ruốc sấy khô liệu ruốc biển tươi sạch sấy khô ...</td>\n",
              "      <td>59420.60320</td>\n",
              "      <td>2.311383</td>\n",
              "      <td>29</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64154689.0</td>\n",
              "      <td>Video hình ảnh mang tính chất nhận xu ạ. \\nSho...</td>\n",
              "      <td>https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...</td>\n",
              "      <td>0.895438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>42004863</td>\n",
              "      <td>huyenpi.kul</td>\n",
              "      <td>10477233552</td>\n",
              "      <td>Quả dâu tây sấy dẻ</td>\n",
              "      <td>dâu_tây sấy dẻo đặc_sản cao_cấp dai dai mềm hư...</td>\n",
              "      <td>29825.88724</td>\n",
              "      <td>2.301471</td>\n",
              "      <td>20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>377287160.0</td>\n",
              "      <td>Jsjsnsjdjkd hình ảnh minh họa ,mang tc nhận xu...</td>\n",
              "      <td>https://shopee.vn/Qu%E1%BA%A3-d%C3%A2u-t%C3%A2...</td>\n",
              "      <td>0.838509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>43086726</td>\n",
              "      <td>TLFood Shop</td>\n",
              "      <td>5806774572</td>\n",
              "      <td>100GR Bò khô xé sợi thơm ngon hàng l</td>\n",
              "      <td>gr bò khô sợi heo giả bò món nhậu lý_tưởng đấn...</td>\n",
              "      <td>15134.89551</td>\n",
              "      <td>1.939551</td>\n",
              "      <td>2675</td>\n",
              "      <td>5.0</td>\n",
              "      <td>772005828.0</td>\n",
              "      <td>Hương vị:nzndjdjdkd như cục đất\\n\\nĐnndnkkwlwk...</td>\n",
              "      <td>https://shopee.vn/100GR-B%C3%B2-kh%C3%B4-x%C3%...</td>\n",
              "      <td>0.826895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>63406509</td>\n",
              "      <td>Đặc Sản Đà Nẵng Chính Gốc</td>\n",
              "      <td>12557561629</td>\n",
              "      <td>100gr CHÀ BÔNG TÔM/ RUỐC TÔM ĐÀ NẴNG - siêu</td>\n",
              "      <td>tôm ruốc tôm đà nẵng siêu ngon đặc_điểm sợi ru...</td>\n",
              "      <td>71966.25222</td>\n",
              "      <td>5.998826</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>257376075.0</td>\n",
              "      <td>Đậm vị quá ngon chất lượng giá hợp lý ship hàn...</td>\n",
              "      <td>https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...</td>\n",
              "      <td>0.823328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2770707</td>\n",
              "      <td>Demacia Station - 39 Thụy Khuê</td>\n",
              "      <td>9539017473</td>\n",
              "      <td>[HÀ NỘI] Xúc Xích Sụn Gà Cay Ăn Liền 1 gói 4 v...</td>\n",
              "      <td>xúc_xích sụn non mới ngon lạ_miệng dai dai cắn...</td>\n",
              "      <td>9262.24843</td>\n",
              "      <td>0.588511</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>404031556.0</td>\n",
              "      <td>Sản phảmmmmm\\nM\\nM\\nMm\\nMm\\nMok\\nOkkkkkkkkkkkk...</td>\n",
              "      <td>https://shopee.vn/-H%C3%80-N%E1%BB%98I-X%C3%BA...</td>\n",
              "      <td>0.819496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29020bef-672d-4cd5-a09a-c8c0f13919a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29020bef-672d-4cd5-a09a-c8c0f13919a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29020bef-672d-4cd5-a09a-c8c0f13919a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}