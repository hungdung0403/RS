{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBwithW2V.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORT TH∆Ø VI·ªÜN V√Ä LOAD DATA"
      ],
      "metadata": {
        "id": "VkE51wiWDMRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjwCfpegXmKh",
        "outputId": "638650cc-a056-4a5c-8b1a-cab4d8c35015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.2)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 965 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.1.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Collecting underthesea-core==0.0.4_alpha.10\n",
            "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 581 kB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.4 underthesea-core-0.0.4a10 unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==3.4.0\n",
            "  Downloading gensim-3.4.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.2 MB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (1.15.0)\n",
            "Requirement already satisfied: smart_open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.4.0) (5.2.1)\n",
            "Building wheels for collected packages: gensim\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gensim: filename=gensim-3.4.0-cp37-cp37m-linux_x86_64.whl size=23316742 sha256=327aa5d23ac5d54ad7f51b2f350c8ed445c96a1f55dcde28c117f83f330d9e20\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/a4/46/4e18f7d25915b16e0e790a5362e455aba6cadc486994806c05\n",
            "Successfully built gensim\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.4.0\n",
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "!pip install underthesea\n",
        "!pip install openpyxl ##engine\n",
        "!pip install gensim==3.4.0\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import class_weight as cw\n",
        "from sklearn import utils\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from underthesea import word_tokenize\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "import multiprocessing\n",
        "# Word2vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "df = pd.read_csv('/content/drive/MyDrive/clab/full.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU"
      ],
      "metadata": {
        "id": "6YdQsKUuDVcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_k_dau(df):\n",
        "    alpha_vn =\"·∫°·∫£√£√†√°√¢·∫≠·∫ß·∫•·∫©·∫´ƒÉ·∫Ø·∫±·∫∑·∫≥·∫µ√≥√≤·ªç√µ·ªè√¥·ªô·ªï·ªó·ªì·ªë∆°·ªù·ªõ·ª£·ªü·ª°√©√®·∫ª·∫π·∫Ω√™·∫ø·ªÅ·ªá·ªÉ·ªÖ√∫√π·ª•·ªß≈©∆∞·ª±·ªØ·ª≠·ª´·ª©√≠√¨·ªã·ªâƒ©√Ω·ª≥·ª∑·ªµ·ªπƒë·∫†·∫¢√É√Ä√Å√Ç·∫¨·∫¶·∫§·∫®·∫™ƒÇ·∫Æ·∫∞·∫∂·∫≤·∫¥√ì√í·ªå√ï·ªé√î·ªò·ªî·ªñ·ªí·ªê∆†·ªú·ªö·ª¢·ªû·ª†√â√à·∫∫·∫∏·∫º√ä·∫æ·ªÄ·ªÜ·ªÇ·ªÑ√ö√ô·ª§·ª¶≈®∆Ø·ª∞·ªÆ·ª¨·ª™·ª®√ç√å·ªä·ªàƒ®√ù·ª≤·ª∂·ª¥·ª∏ƒê\"\n",
        "    index=[]\n",
        "    for i,text in enumerate(df.comment.astype(str)):\n",
        "        words = text.split(' ')\n",
        "        k_dau = []\n",
        "        if len(words) >=5:\n",
        "            for word in words:\n",
        "                for char in alpha_vn:\n",
        "                    if char in word:\n",
        "                        k_dau.append(word)  \n",
        "            if len(k_dau)==0:\n",
        "                index.append(i)    \n",
        "    df=df.drop(index,axis=0)\n",
        "    return df\n",
        "\n",
        "dic = pd.read_excel('/content/dictionary_new.xlsx','Sheet1')\n",
        "fullcom = dic.set_index('Short').T.to_dict('list')# bi·∫øn ƒë·ªïi c√¢u c√≥ t·ª´ vi·∫øt t·∫Øt th√†nh c√¢u ho√†n ch·ªânh\n",
        "def slang(text) : \n",
        "    result = []\n",
        "    for word in text.split() : \n",
        "        try :\n",
        "            word = fullcom[word][0]\n",
        "            result.append(word)\n",
        "        except :\n",
        "            result.append(word)\n",
        "\n",
        "    sentence=' '.join(word for word in result)\n",
        "    return sentence\n",
        "# t·∫°o stopword\n",
        "with open('/content/vietnamese_stopword_2.txt') as f:\n",
        "    data = f.read()\n",
        "new_stopword = [ ]\n",
        "stopword_list = [line for line in data.split('\\n') if line != '']\n",
        "stopword_list=stopword_list + new_stopword\n",
        "stop_word= set(stopword_list)\n",
        "stop_words=[]\n",
        "for word in stop_word:\n",
        "    stop_words.append(word.replace(\" \",\"_\"))\n",
        "# t·∫°o elongated: vuiiii -> vui\n",
        "import re\n",
        "from itertools import groupby\n",
        "\n",
        "# X√≥a emoji\n",
        "def remove_emojis(data):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', data)\n",
        "#Lo·∫°i b·ªè spam : \n",
        "def spam(text) :\n",
        "    sentence = []\n",
        "    for word in text.split() :\n",
        "        if len(word) < 6 :\n",
        "           sentence.append(word) \n",
        "        else :\n",
        "            word = \" \"    \n",
        "    sentence=' '.join(word for word in sentence)\n",
        "    return sentence\n",
        "\n",
        "# bi·∫øn ƒë·ªïi c√¢u c√≥ t·ª´ vi·∫øt t·∫Øt th√†nh c√¢u ho√†n ch·ªânh\n",
        "def slang(text) : \n",
        "    result = []\n",
        "    for word in text.split() : \n",
        "        try :\n",
        "            word = fullcom[word][0]\n",
        "            result.append(word)\n",
        "        except :\n",
        "            result.append(word)\n",
        "\n",
        "    sentence=' '.join(word for word in result)\n",
        "    return sentence\n",
        "# d√πng th∆∞ vi·ªán underthesea ƒë·ªÉ n·ªëi t·ª´\n",
        "def convert_word_tokenize(text):\n",
        "    return word_tokenize(text,format='text')\n",
        "\n",
        "def elongated_remove(text):\n",
        "    return ''.join(c for c, _ in groupby(text))\n",
        "\n",
        "# t·∫°o negation: v√≠ d·ª• c√¢u: T√¥i kh√¥ng th√≠ch ƒëi h·ªçc -> T√¥i kh√¥ng_th√≠ch ƒëi h·ªçc\n",
        "def negation_handling(text):\n",
        "    negation = False\n",
        "    result = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        stripped = word.strip().lower()\n",
        "        negated = \"kh√¥ng_\" + stripped if negation else stripped\n",
        "        if negation == True:\n",
        "            negation = not negation\n",
        "        result.append(negated)\n",
        "        if any(neg == word for neg in [\"kh√¥ng\",\"ch∆∞a\",\"ch·∫≥ng\",\"ch·∫£\",\"ƒë·ª´ng\"\n",
        "                                       \"Kh√¥ng\",\"Ch∆∞a\",\"Ch·∫£\",\"Ch·∫≥ng\",\"ƒê·ª´ng\"]):\n",
        "            negation = not negation\n",
        "    for word in result:\n",
        "        if word in [\"kh√¥ng\",\"ch∆∞a\",\"ch·∫≥ng\",\"ch·∫£\",\"ƒë·ª´ng\"\n",
        "                    \"Kh√¥ng\",\"Ch∆∞a\",\"Ch·∫£\",\"Ch·∫≥ng\",\"ƒê·ª´ng\"]:\n",
        "            result.remove(word)\n",
        "    result = ' '.join(result)\n",
        "    return result\n",
        "\n",
        "# t·∫°o intensification: v√≠ d·ª• c√¢u: T√¥i r·∫•t th√≠ch ƒëi h·ªçc -> T√¥i r·∫•t_th√≠ch ƒëi h·ªçc\n",
        "def intensification_handling(text):\n",
        "    negation = False\n",
        "    result = []\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        stripped = word.strip().lower()\n",
        "        negated = \"r·∫•t_\" + stripped if negation else stripped\n",
        "        if negation == True:\n",
        "            negation = not negation\n",
        "        result.append(negated)\n",
        "        if any(neg == word for neg in [\"r·∫•t\",\"kh√°\",\"h∆°i\",\"qu√°\",\"to√†n\",\n",
        "                                      \"R·∫•t\",\"Kh√°\",\"H∆°i\",\"Qu√°\",\"To√†n\"]):\n",
        "            negation = not negation\n",
        "    for word in result:\n",
        "        if word in ['r·∫•t','h∆°i','kh√°','qu√°','to√†n',\n",
        "                   \"R·∫•t\",\"Kh√°\",\"H∆°i\",\"Qu√°\",\"To√†n\"]:\n",
        "            result.remove(word)\n",
        "    result = ' '.join(result)\n",
        "    return result\n",
        "  # X√≥a code html\n",
        "def remove_html(txt):\n",
        "    return re.sub(r'<[^>]*>', '', txt)\n",
        "\n",
        "# x√≥a link\n",
        "def remove_url(document):\n",
        "    document = re.sub(r\"(http\\S+)|(www\\S+)\", '', document)\n",
        "    return document\n",
        "\n",
        "# x√≥a tag user\n",
        "def remove_tag_user(document):\n",
        "    document = re.sub(r\"(@\\w{1,15})\", '', document)\n",
        "    return document\n",
        "\n",
        "# x√≥a hashtags\n",
        "def remove_hashtags(document):\n",
        "    document = re.sub(\"#(\\w{1,})\", '', document)\n",
        "    return document\n",
        "\n",
        "# Chu·∫©n h√≥a unicode\n",
        "import regex as re\n",
        "uniChars = \"√†√°·∫£√£·∫°√¢·∫ß·∫•·∫©·∫´·∫≠ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªáƒë√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ√Ä√Å·∫¢√É·∫†√Ç·∫¶·∫§·∫®·∫™·∫¨ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂√à√â·∫∫·∫º·∫∏√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜƒê√å√ç·ªàƒ®·ªä√í√ì·ªé√ï·ªå√î·ªí·ªê·ªî·ªñ·ªò∆†·ªú·ªö·ªû·ª†·ª¢√ô√ö·ª¶≈®·ª§∆Ø·ª™·ª®·ª¨·ªÆ·ª∞·ª≤√ù·ª∂·ª∏·ª¥√ÇƒÇƒê√î∆†∆Ø\"\n",
        "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
        "def loaddicchar():\n",
        "    dic = {}\n",
        "    char1252 = 'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£'.split(\n",
        "        '|')\n",
        "    charutf8 = \"√†|√°|·∫£|√£|·∫°|·∫ß|·∫•|·∫©|·∫´|·∫≠|·∫±|·∫Ø|·∫≥|·∫µ|·∫∑|√®|√©|·∫ª|·∫Ω|·∫π|·ªÅ|·∫ø|·ªÉ|·ªÖ|·ªá|√¨|√≠|·ªâ|ƒ©|·ªã|√≤|√≥|·ªè|√µ|·ªç|·ªì|·ªë|·ªï|·ªó|·ªô|·ªù|·ªõ|·ªü|·ª°|·ª£|√π|√∫|·ªß|≈©|·ª•|·ª´|·ª©|·ª≠|·ªØ|·ª±|·ª≥|√Ω|·ª∑|·ªπ|·ªµ|√Ä|√Å|·∫¢|√É|·∫†|·∫¶|·∫§|·∫®|·∫™|·∫¨|·∫∞|·∫Æ|·∫≤|·∫¥|·∫∂|√à|√â|·∫∫|·∫º|·∫∏|·ªÄ|·∫æ|·ªÇ|·ªÑ|·ªÜ|√å|√ç|·ªà|ƒ®|·ªä|√í|√ì|·ªé|√ï|·ªå|·ªí|·ªê|·ªî|·ªñ|·ªò|·ªú|·ªö|·ªû|·ª†|·ª¢|√ô|√ö|·ª¶|≈®|·ª§|·ª™|·ª®|·ª¨|·ªÆ|·ª∞|·ª≤|√ù|·ª∂|·ª∏|·ª¥\".split(\n",
        "        '|')\n",
        "    for i in range(len(char1252)):\n",
        "        dic[char1252[i]] = charutf8[i]\n",
        "    return dic\n",
        "dicchar = loaddicchar()\n",
        "def convert_unicode(txt):\n",
        "    return re.sub(\n",
        "        r'aÃÄ|aÃÅ|aÃâ|aÃÉ|aÃ£|√¢ÃÄ|√¢ÃÅ|√¢Ãâ|√¢ÃÉ|√¢Ã£|ƒÉÃÄ|ƒÉÃÅ|ƒÉÃâ|ƒÉÃÉ|ƒÉÃ£|eÃÄ|eÃÅ|eÃâ|eÃÉ|eÃ£|√™ÃÄ|√™ÃÅ|√™Ãâ|√™ÃÉ|√™Ã£|iÃÄ|iÃÅ|iÃâ|iÃÉ|iÃ£|oÃÄ|oÃÅ|oÃâ|oÃÉ|oÃ£|√¥ÃÄ|√¥ÃÅ|√¥Ãâ|√¥ÃÉ|√¥Ã£|∆°ÃÄ|∆°ÃÅ|∆°Ãâ|∆°ÃÉ|∆°Ã£|uÃÄ|uÃÅ|uÃâ|uÃÉ|uÃ£|∆∞ÃÄ|∆∞ÃÅ|∆∞Ãâ|∆∞ÃÉ|∆∞Ã£|yÃÄ|yÃÅ|yÃâ|yÃÉ|yÃ£|AÃÄ|AÃÅ|AÃâ|AÃÉ|AÃ£|√ÇÃÄ|√ÇÃÅ|√ÇÃâ|√ÇÃÉ|√ÇÃ£|ƒÇÃÄ|ƒÇÃÅ|ƒÇÃâ|ƒÇÃÉ|ƒÇÃ£|EÃÄ|EÃÅ|EÃâ|EÃÉ|EÃ£|√äÃÄ|√äÃÅ|√äÃâ|√äÃÉ|√äÃ£|IÃÄ|IÃÅ|IÃâ|IÃÉ|IÃ£|OÃÄ|OÃÅ|OÃâ|OÃÉ|OÃ£|√îÃÄ|√îÃÅ|√îÃâ|√îÃÉ|√îÃ£|∆†ÃÄ|∆†ÃÅ|∆†Ãâ|∆†ÃÉ|∆†Ã£|UÃÄ|UÃÅ|UÃâ|UÃÉ|UÃ£|∆ØÃÄ|∆ØÃÅ|∆ØÃâ|∆ØÃÉ|∆ØÃ£|YÃÄ|YÃÅ|YÃâ|YÃÉ|YÃ£',\n",
        "        lambda x: dicchar[x.group()], txt)\n",
        "\n",
        "# Chu·∫©n h√≥a d·∫•u ti·∫øng vi·ªát\n",
        "bang_nguyen_am = [['a', '√†', '√°', '·∫£', '√£', '·∫°', 'a'],\n",
        "                  ['ƒÉ', '·∫±', '·∫Ø', '·∫≥', '·∫µ', '·∫∑', 'aw'],\n",
        "                  ['√¢', '·∫ß', '·∫•', '·∫©', '·∫´', '·∫≠', 'aa'],\n",
        "                  ['e', '√®', '√©', '·∫ª', '·∫Ω', '·∫π', 'e'],\n",
        "                  ['√™', '·ªÅ', '·∫ø', '·ªÉ', '·ªÖ', '·ªá', 'ee'],\n",
        "                  ['i', '√¨', '√≠', '·ªâ', 'ƒ©', '·ªã', 'i'],\n",
        "                  ['o', '√≤', '√≥', '·ªè', '√µ', '·ªç', 'o'],\n",
        "                  ['√¥', '·ªì', '·ªë', '·ªï', '·ªó', '·ªô', 'oo'],\n",
        "                  ['∆°', '·ªù', '·ªõ', '·ªü', '·ª°', '·ª£', 'ow'],\n",
        "                  ['u', '√π', '√∫', '·ªß', '≈©', '·ª•', 'u'],\n",
        "                  ['∆∞', '·ª´', '·ª©', '·ª≠', '·ªØ', '·ª±', 'uw'],\n",
        "                  ['y', '·ª≥', '√Ω', '·ª∑', '·ªπ', '·ªµ', 'y']]\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "nguyen_am_to_ids = {}\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9: \n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5: \n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  \n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            return ''.join(chars)\n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "        else:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    return ''.join(chars)\n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Chuy·ªÉn 100k th√†nh gi√° ti·ªÅn\n",
        "def money(text):\n",
        "    text = re.sub('(\\d+k)|(\\d+ k)|(\\d+ƒë·ªìng)|(\\d+ ƒë·ªìng)|(\\d+ng√†n)|(\\d+ ng√†n)|(\\d+ngh√¨n)|(\\d+ ngh√¨n)', 'gi√°_ti·ªÅn', text)\n",
        "    return text# X√≥a code html\n",
        "\n",
        "def remove_stopword(text):\n",
        "    sentence=[]\n",
        "    for word in text.split():\n",
        "        if word not in stop_words:\n",
        "            sentence.append(word)\n",
        "    sentence= ' '.join(word for word in sentence)\n",
        "    return sentence\n",
        "# x√≥a s·ªë trong c√¢u\n",
        "def clean_number_object(string: str, punctuations=r'''!+()-[]{};:'\"\\,<>./?@#$%^&~1234657890''') -> str:\n",
        "    # X√≥a s·ªë\n",
        "    for x in string.lower(): \n",
        "        if x in punctuations: \n",
        "            string = string.replace(x, \"\") \n",
        "    return string\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLuQ83fwfTpX",
        "outputId": "924d7e36-fbb8-4a2a-d601-0b495c045eca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(data_comment):\n",
        "    new_comment=[]\n",
        "    for text in data_comment:\n",
        "        text = remove_emojis(text)\n",
        "        text = remove_html(text)\n",
        "        text = remove_url(text)\n",
        "        text = remove_tag_user(text)\n",
        "        text = remove_hashtags(text)\n",
        "        text = elongated_remove(text)\n",
        "        text = chuan_hoa_dau_cau_tieng_viet(text)\n",
        "        text = spam(text)\n",
        "        text = money(text)\n",
        "        text = slang(text)\n",
        "        text = convert_unicode(text)\n",
        "        text = clean_number_object(text)\n",
        "        text = intensification_handling(text)\n",
        "        text = negation_handling(text)\n",
        "        text = convert_word_tokenize(text)\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\s\\w√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√≠√¨·ªâƒ©·ªã√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë_]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        text = remove_stopword(text)\n",
        "        new_comment.append(text)\n",
        "    return new_comment"
      ],
      "metadata": {
        "id": "F8whHjsNfmBs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.drop_duplicates(subset='Description_Prod')\n",
        "df1 = df1.drop(columns=['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'Description_Product', 'Index'])\n",
        "df1 = df1.dropna(subset=[\"User_id\", \"User_Rating\", \"Prod_id\"])\n",
        "df1 = df1.reset_index()\n",
        "df1 = df1.drop(columns='index')\n",
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2_4PUeEZwWz",
        "outputId": "9a614e74-0fb6-485f-cbdf-a73e088a96da"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 598 entries, 0 to 597\n",
            "Data columns (total 12 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Shop_id           598 non-null    int64  \n",
            " 1   Shop_Name         598 non-null    object \n",
            " 2   Prod_id           598 non-null    int64  \n",
            " 3   Prod_Name         598 non-null    object \n",
            " 4   Description_Prod  598 non-null    object \n",
            " 5   Price             598 non-null    float64\n",
            " 6   Average_Rating    598 non-null    float64\n",
            " 7   Total_Comments    598 non-null    int64  \n",
            " 8   User_Rating       598 non-null    float64\n",
            " 9   User_id           598 non-null    float64\n",
            " 10  User_Review       595 non-null    object \n",
            " 11  URL               598 non-null    object \n",
            "dtypes: float64(4), int64(3), object(5)\n",
            "memory usage: 56.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1['Description_Prod'] = pre_process(df1['Description_Prod'].astype(str))"
      ],
      "metadata": {
        "id": "hWIn81wPfuTn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TFIDF"
      ],
      "metadata": {
        "id": "zmX4cBfn_WVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_name_food_(index):\n",
        "    return df1['Prod_Name'].iloc[index]"
      ],
      "metadata": {
        "id": "OFcZ-HsuEszL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "def recommendation_system_food_using_TFTDF_(food_id, number):\n",
        "  # food index mapping\n",
        "  mapping1 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "  id1 = mapping1[food_id]\n",
        "  #print('Id1:',id1)\n",
        "  #print('List mapping of product name:\\n',mapping)\n",
        "  product1 = mapping1.index[id1]\n",
        "  #print(product1)\n",
        "\n",
        "  demo_id1 = mapping1.get(key = product1)\n",
        "  #print('Demo_id1:',demo_id1)\n",
        "  mapping2 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "  id2 = mapping2.get(key = product1)\n",
        "  #print('Id2:',id2)\n",
        "  product2 = mapping2.index[id2]\n",
        "  #print(product2)\n",
        "\n",
        "\n",
        "  # TF-TDF\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_vectorizer = vectorizer.fit(df1['Description_Prod'])\n",
        "  #print(tfidf_vectorizer)\n",
        "\n",
        "  overview_matrix = tfidf_vectorizer.transform(df1['Description_Prod'])\n",
        "  #print(overview_matrix)\n",
        "  #print('Overview_matrix shape:',overview_matrix.shape)\n",
        "\n",
        "  similarity_matrix = linear_kernel(overview_matrix, overview_matrix)\n",
        "  #print('Similarity_matrix:\\n',similarity_matrix)\n",
        "  #print('Similarity_matrix shape:',similarity_matrix.shape)\n",
        "\n",
        "  # Recommendation\n",
        "  print('Product name users need to recommend to them:\\n', product2)\n",
        "  similarity_score = list(enumerate(similarity_matrix[id2]))\n",
        "  global foodname\n",
        "  foodname = product2\n",
        "\n",
        "  similarity_score = sorted(similarity_score, key = lambda x: x[1], reverse = True)\n",
        "  similarity_score = similarity_score[1:21]\n",
        "  recommendation = [(get_name_food_(id) , score) for id, score in similarity_score]\n",
        "\n",
        "  # Xu·∫•t ra danh s√°ch top 10 s·∫£n ph·∫©m ƒë∆∞·ª£c khuy·∫øn ngh·ªã cho ng∆∞·ªùi d√πng v·ªõi m·ªôt s·∫£n ph·∫©m ch·ªâ ƒë·ªãnh d∆∞·ªõi d·∫°ng b·∫£ng\n",
        "  recommendation_df = pd.DataFrame(recommendation, columns=['Prod_Name','Cosine_similarity'])\n",
        "  recommendation_df = pd.merge(df1, recommendation_df, on=\"Prod_Name\", how=\"inner\")\n",
        "  recommendation_df = recommendation_df.sort_values(by=['Cosine_similarity'],ascending=False)\n",
        "  recommendation_df = recommendation_df.head(number)\n",
        "  print(recommendation_df['Prod_Name'])\n",
        "\n",
        "  return recommendation_df"
      ],
      "metadata": {
        "id": "JfYu6w2k_TW9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_system_food_using_TFTDF_(200, 5)"
      ],
      "metadata": {
        "id": "rfh6cQMaATbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "17659abb-3752-42a0-f57f-4a9093d2b8e4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product name users need to recommend to them:\n",
            " H·ªß 200gr ru·ªëc x·∫•y ngon s·ªë 1 T√ÇY NINH d√πng chung b√°nh \n",
            "18                           500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤\n",
            "13    {Ru·ªëc g√† th·ªãt t∆∞∆°i üíØ}H·∫°nh G√†/ Ru·ªëc G√† - ch√† b√¥...\n",
            "16                 ƒê·ªì ƒÇn Nhanh Ru·ªëc C√° Ch√©p,Ch√† B√¥ng C√°\n",
            "19          100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u\n",
            "11                     H·ªß 300G Ru·ªëc S·∫•y H√†nh Phi Tr·ªçng \n",
            "Name: Prod_Name, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Shop_id                  Shop_Name      Prod_id  \\\n",
              "18  237204869          dacsanphanrangso1   9207719667   \n",
              "13   50421059                    H·∫°nh G√†   2767491558   \n",
              "16  667449329         TH·∫¢O M·ªòC ƒê·ªíNG XANH  17103008545   \n",
              "19   63406509  ƒê·∫∑c S·∫£n ƒê√† N·∫µng Ch√≠nh G·ªëc  12557561629   \n",
              "11   17447969     B√ÅNH TR√ÅNG TR·ªåNG NGHƒ®A    247272852   \n",
              "\n",
              "                                            Prod_Name  \\\n",
              "18                         500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤   \n",
              "13  {Ru·ªëc g√† th·ªãt t∆∞∆°i üíØ}H·∫°nh G√†/ Ru·ªëc G√† - ch√† b√¥...   \n",
              "16               ƒê·ªì ƒÇn Nhanh Ru·ªëc C√° Ch√©p,Ch√† B√¥ng C√°   \n",
              "19        100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u   \n",
              "11                   H·ªß 300G Ru·ªëc S·∫•y H√†nh Phi Tr·ªçng    \n",
              "\n",
              "                                     Description_Prod         Price  \\\n",
              "18  ru·ªëc s·∫•y kh√¥ li·ªáu ru·ªëc bi·ªÉn t∆∞∆°i s·∫°ch s·∫•y kh√¥ ...   59420.60320   \n",
              "13  ru·ªëc g√† gi√£ b·∫±ng g√† t∆∞∆°i n√™n s·ª£i ru·ªëc ƒÉn th∆°m ...  160283.04651   \n",
              "16  th√¥ng_tin s·∫£n_ph·∫©m ru·ªëc c√° ch√©p ru·ªëc h·ª£p_t√°c_x...  327683.30011   \n",
              "19  t√¥m ru·ªëc t√¥m ƒë√† n·∫µng si√™u ngon ƒë·∫∑c_ƒëi·ªÉm s·ª£i ru...   71966.25222   \n",
              "11  ru·ªëc s·∫•y h√†nh phi th√†nh_ph·∫ßn ru·ªëc h√†nh phi_h√†n...   95462.18337   \n",
              "\n",
              "    Average_Rating  Total_Comments  User_Rating      User_id  \\\n",
              "18        2.311383              29          5.0   64154689.0   \n",
              "13        2.087949              26          5.0   38479513.0   \n",
              "16        2.739733               2          5.0  471091541.0   \n",
              "19        5.998826               2          5.0  257376075.0   \n",
              "11        4.902445              21          4.0   44504253.0   \n",
              "\n",
              "                                          User_Review  \\\n",
              "18  Video h√¨nh ·∫£nh mang t√≠nh ch·∫•t nh·∫≠n xu ·∫°. \\nSho...   \n",
              "13  Ru·ªëc ngon l·∫Øm, ai ƒÉn nh·∫°t th√¨ v·ª´a c√≤n ai ai ƒÉn...   \n",
              "16  Giao h√†ng nhanh, ru·ªëc th∆°m, ngon. Nh∆∞ng thi th...   \n",
              "19  ƒê·∫≠m v·ªã qu√° ngon ch·∫•t l∆∞·ª£ng gi√° h·ª£p l√Ω ship h√†n...   \n",
              "11  M√¨nh ƒÉn v√†o l·∫°i th·∫•y c√≥ v·ªã nh·∫´n ko bi·∫øt nguy√™n...   \n",
              "\n",
              "                                                  URL  Cosine_similarity  \n",
              "18  https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...           0.465455  \n",
              "13  https://shopee.vn/-Ru%E1%BB%91c-g%C3%A0-th%E1%...           0.427757  \n",
              "16  https://shopee.vn/%C4%90%E1%BB%93-%C4%82n-Nhan...           0.397616  \n",
              "19  https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...           0.367723  \n",
              "11  https://shopee.vn/H%E1%BB%A7-300G-Ru%E1%BB%91c...           0.329758  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Shop_id</th>\n",
              "      <th>Shop_Name</th>\n",
              "      <th>Prod_id</th>\n",
              "      <th>Prod_Name</th>\n",
              "      <th>Description_Prod</th>\n",
              "      <th>Price</th>\n",
              "      <th>Average_Rating</th>\n",
              "      <th>Total_Comments</th>\n",
              "      <th>User_Rating</th>\n",
              "      <th>User_id</th>\n",
              "      <th>User_Review</th>\n",
              "      <th>URL</th>\n",
              "      <th>Cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>237204869</td>\n",
              "      <td>dacsanphanrangso1</td>\n",
              "      <td>9207719667</td>\n",
              "      <td>500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤</td>\n",
              "      <td>ru·ªëc s·∫•y kh√¥ li·ªáu ru·ªëc bi·ªÉn t∆∞∆°i s·∫°ch s·∫•y kh√¥ ...</td>\n",
              "      <td>59420.60320</td>\n",
              "      <td>2.311383</td>\n",
              "      <td>29</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64154689.0</td>\n",
              "      <td>Video h√¨nh ·∫£nh mang t√≠nh ch·∫•t nh·∫≠n xu ·∫°. \\nSho...</td>\n",
              "      <td>https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...</td>\n",
              "      <td>0.465455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>50421059</td>\n",
              "      <td>H·∫°nh G√†</td>\n",
              "      <td>2767491558</td>\n",
              "      <td>{Ru·ªëc g√† th·ªãt t∆∞∆°i üíØ}H·∫°nh G√†/ Ru·ªëc G√† - ch√† b√¥...</td>\n",
              "      <td>ru·ªëc g√† gi√£ b·∫±ng g√† t∆∞∆°i n√™n s·ª£i ru·ªëc ƒÉn th∆°m ...</td>\n",
              "      <td>160283.04651</td>\n",
              "      <td>2.087949</td>\n",
              "      <td>26</td>\n",
              "      <td>5.0</td>\n",
              "      <td>38479513.0</td>\n",
              "      <td>Ru·ªëc ngon l·∫Øm, ai ƒÉn nh·∫°t th√¨ v·ª´a c√≤n ai ai ƒÉn...</td>\n",
              "      <td>https://shopee.vn/-Ru%E1%BB%91c-g%C3%A0-th%E1%...</td>\n",
              "      <td>0.427757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>667449329</td>\n",
              "      <td>TH·∫¢O M·ªòC ƒê·ªíNG XANH</td>\n",
              "      <td>17103008545</td>\n",
              "      <td>ƒê·ªì ƒÇn Nhanh Ru·ªëc C√° Ch√©p,Ch√† B√¥ng C√°</td>\n",
              "      <td>th√¥ng_tin s·∫£n_ph·∫©m ru·ªëc c√° ch√©p ru·ªëc h·ª£p_t√°c_x...</td>\n",
              "      <td>327683.30011</td>\n",
              "      <td>2.739733</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>471091541.0</td>\n",
              "      <td>Giao h√†ng nhanh, ru·ªëc th∆°m, ngon. Nh∆∞ng thi th...</td>\n",
              "      <td>https://shopee.vn/%C4%90%E1%BB%93-%C4%82n-Nhan...</td>\n",
              "      <td>0.397616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63406509</td>\n",
              "      <td>ƒê·∫∑c S·∫£n ƒê√† N·∫µng Ch√≠nh G·ªëc</td>\n",
              "      <td>12557561629</td>\n",
              "      <td>100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u</td>\n",
              "      <td>t√¥m ru·ªëc t√¥m ƒë√† n·∫µng si√™u ngon ƒë·∫∑c_ƒëi·ªÉm s·ª£i ru...</td>\n",
              "      <td>71966.25222</td>\n",
              "      <td>5.998826</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>257376075.0</td>\n",
              "      <td>ƒê·∫≠m v·ªã qu√° ngon ch·∫•t l∆∞·ª£ng gi√° h·ª£p l√Ω ship h√†n...</td>\n",
              "      <td>https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...</td>\n",
              "      <td>0.367723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>17447969</td>\n",
              "      <td>B√ÅNH TR√ÅNG TR·ªåNG NGHƒ®A</td>\n",
              "      <td>247272852</td>\n",
              "      <td>H·ªß 300G Ru·ªëc S·∫•y H√†nh Phi Tr·ªçng</td>\n",
              "      <td>ru·ªëc s·∫•y h√†nh phi th√†nh_ph·∫ßn ru·ªëc h√†nh phi_h√†n...</td>\n",
              "      <td>95462.18337</td>\n",
              "      <td>4.902445</td>\n",
              "      <td>21</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44504253.0</td>\n",
              "      <td>M√¨nh ƒÉn v√†o l·∫°i th·∫•y c√≥ v·ªã nh·∫´n ko bi·∫øt nguy√™n...</td>\n",
              "      <td>https://shopee.vn/H%E1%BB%A7-300G-Ru%E1%BB%91c...</td>\n",
              "      <td>0.329758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f87c074a-0f65-4de2-9fc9-d2e7eb5180a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WORD2VEC"
      ],
      "metadata": {
        "id": "MvwBpa9RENZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cores=multiprocessing.cpu_count()\n",
        "\n",
        "# model d√πng Bag of word\n",
        "SEED = 455 # random\n",
        "W2V_SIZE = 400\n",
        "W2V_WINDOW = 9 # max distance bt the current and predicted\n",
        "W2V_EPOCH = 35 \n",
        "W2V_MIN_COUNT = 6 # Ignore word frequence < n\n",
        "\n",
        "w2v_model = Word2Vec(   seed=SEED, \n",
        "                        size=W2V_SIZE,\n",
        "                        window=W2V_WINDOW,\n",
        "                        min_count=W2V_MIN_COUNT,\n",
        "                        workers=cores\n",
        "                        )"
      ],
      "metadata": {
        "id": "LtT2-FmPX0MU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [_text.split() for _text in df1['Description_Prod'].astype(str)]"
      ],
      "metadata": {
        "id": "l5doahtKYuzQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "w2v_model.build_vocab(tqdm(documents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IABge7SAdsMA",
        "outputId": "77ead24d-c330-4d46-e45d-425e9738dfd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 598/598 [00:00<00:00, 34281.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohq3h6coYxKd",
        "outputId": "05d51fb7-b0f5-46d6-8cf1-8489e5c4de9e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1787283, 2356165)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.most_similar('ngon',topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RctazM9Y0rF",
        "outputId": "c539c9d4-f453-44b4-c523-0d3eceed3b7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dai', 0.7435066103935242),\n",
              " ('b·∫°ch_tu·ªôc', 0.6610574722290039),\n",
              " ('th∆°m', 0.6519355177879333),\n",
              " ('ƒë·∫≠m_ƒë√†', 0.6159470081329346),\n",
              " ('h∆∞∆°ng_v·ªã', 0.6060012578964233),\n",
              " ('h·∫•p_d·∫´n', 0.6024566292762756),\n",
              " ('ƒë·∫∑c_tr∆∞ng', 0.5924603939056396),\n",
              " ('r√¢u', 0.5866954326629639),\n",
              " ('kh√¥ng_l·∫´n', 0.5854678153991699),\n",
              " ('m√πi', 0.5647065043449402)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.init_sims(replace=True)\n",
        "print(w2v_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxYhrvNhhQJL",
        "outputId": "b592a221-199b-4c92-e6ba-cd01bfedfa2d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=1599, size=400, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectors(df1):\n",
        "    \n",
        "    # Creating a list for storing the vectors ('Description' into vectors)\n",
        "    global word_embeddings\n",
        "    word_embeddings = []\n",
        "\n",
        "    # Reading the each 'Description'\n",
        "    for line in df1['Description_Prod']:\n",
        "        avgword2vec = None\n",
        "        count = 0\n",
        "        for word in line.split():\n",
        "            if word in w2v_model.wv.vocab:\n",
        "                count += 1\n",
        "                if avgword2vec is None:\n",
        "                    avgword2vec = w2v_model[word]\n",
        "                else:\n",
        "                    avgword2vec = avgword2vec + w2v_model[word]\n",
        "                \n",
        "        if avgword2vec is not None:\n",
        "            avgword2vec = avgword2vec / count\n",
        "            word_embeddings.append(avgword2vec)"
      ],
      "metadata": {
        "id": "qX7F0OCvhZXM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "# Recommending the Top 10 similar food\n",
        "def recommendation_system_food_using_W2v_(prod_id, number):\n",
        "\n",
        "    # food index mapping\n",
        "    mapping1 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "    id1 = mapping1[prod_id]\n",
        "    #print('List mapping of product name:\\n',mapping)\n",
        "    product1 = mapping1.index[id1]\n",
        "\n",
        "    demo_id1 = mapping1.get(key = product1)\n",
        "    mapping2 = pd.Series(df1.index, index = df1['Prod_Name'])\n",
        "    id2 = mapping2.get(key = product1)\n",
        "    product2 = mapping2.index[id2]\n",
        "  \n",
        "    global foodname\n",
        "    foodname = product2\n",
        "    # Calling the function vectors\n",
        "    vectors(df1)\n",
        "    # Finding cosine similarity for the vectors\n",
        "    similarity_matrix = cosine_similarity(word_embeddings, word_embeddings)\n",
        "    #similarity_matrix = linear_kernel(word_embeddings, word_embeddings)\n",
        "\n",
        "\n",
        "    # Recommendation\n",
        "    print('Product name users need to recommend to them:\\n', product2)\n",
        "    similarity_score = list(enumerate(similarity_matrix[id2]))\n",
        "    similarity_score = sorted(similarity_score, key = lambda x: x[1], reverse = True)\n",
        "    similarity_score = similarity_score[1:21]\n",
        "    recommendation = [(get_name_food_(id) , score) for id, score in similarity_score]\n",
        "    # Xu·∫•t ra danh s√°ch top 10 s·∫£n ph·∫©m ƒë∆∞·ª£c khuy·∫øn ngh·ªã cho ng∆∞·ªùi d√πng v·ªõi m·ªôt s·∫£n ph·∫©m ch·ªâ ƒë·ªãnh d∆∞·ªõi d·∫°ng b·∫£ng\n",
        "    recommendation_df = pd.DataFrame(recommendation, columns=['Prod_Name','Cosine_similarity'])\n",
        "    recommendation_df = pd.merge(df1, recommendation_df, on=\"Prod_Name\", how=\"inner\")\n",
        "    recommendation_df = recommendation_df.sort_values(by=['Cosine_similarity'],ascending=False)\n",
        "    recommendation_df = recommendation_df.head(number)\n",
        "    print(recommendation_df['Prod_Name'])\n",
        "    return recommendation_df\n"
      ],
      "metadata": {
        "id": "XNXzy-Fwhh5O"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_system_food_using_W2v_(200, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "Ag8bpWji68MS",
        "outputId": "69e01102-13ba-4fb8-8ac1-f864be71e9cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product name users need to recommend to them:\n",
            " H·ªß 200gr ru·ªëc x·∫•y ngon s·ªë 1 T√ÇY NINH d√πng chung b√°nh \n",
            "13                           500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤\n",
            "16                                   Qu·∫£ d√¢u t√¢y s·∫•y d·∫ª\n",
            "8                  100GR B√≤ kh√¥ x√© s·ª£i th∆°m ngon h√†ng l\n",
            "18          100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u\n",
            "11    [H√Ä N·ªòI] X√∫c X√≠ch S·ª•n G√† Cay ƒÇn Li·ªÅn 1 g√≥i 4 v...\n",
            "Name: Prod_Name, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Shop_id                       Shop_Name      Prod_id  \\\n",
              "13  237204869               dacsanphanrangso1   9207719667   \n",
              "16   42004863                     huyenpi.kul  10477233552   \n",
              "8    43086726                     TLFood Shop   5806774572   \n",
              "18   63406509       ƒê·∫∑c S·∫£n ƒê√† N·∫µng Ch√≠nh G·ªëc  12557561629   \n",
              "11    2770707  Demacia Station - 39 Th·ª•y Khu√™   9539017473   \n",
              "\n",
              "                                            Prod_Name  \\\n",
              "13                         500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤   \n",
              "16                                 Qu·∫£ d√¢u t√¢y s·∫•y d·∫ª   \n",
              "8                100GR B√≤ kh√¥ x√© s·ª£i th∆°m ngon h√†ng l   \n",
              "18        100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u   \n",
              "11  [H√Ä N·ªòI] X√∫c X√≠ch S·ª•n G√† Cay ƒÇn Li·ªÅn 1 g√≥i 4 v...   \n",
              "\n",
              "                                     Description_Prod        Price  \\\n",
              "13  ru·ªëc s·∫•y kh√¥ li·ªáu ru·ªëc bi·ªÉn t∆∞∆°i s·∫°ch s·∫•y kh√¥ ...  59420.60320   \n",
              "16  d√¢u_t√¢y s·∫•y d·∫ªo ƒë·∫∑c_s·∫£n cao_c·∫•p dai dai m·ªÅm h∆∞...  29825.88724   \n",
              "8   gr b√≤ kh√¥ s·ª£i heo gi·∫£ b√≤ m√≥n nh·∫≠u l√Ω_t∆∞·ªüng ƒë·∫•n...  15134.89551   \n",
              "18  t√¥m ru·ªëc t√¥m ƒë√† n·∫µng si√™u ngon ƒë·∫∑c_ƒëi·ªÉm s·ª£i ru...  71966.25222   \n",
              "11  x√∫c_x√≠ch s·ª•n non m·ªõi ngon l·∫°_mi·ªáng dai dai c·∫Øn...   9262.24843   \n",
              "\n",
              "    Average_Rating  Total_Comments  User_Rating      User_id  \\\n",
              "13        2.311383              29          5.0   64154689.0   \n",
              "16        2.301471              20          5.0  377287160.0   \n",
              "8         1.939551            2675          5.0  772005828.0   \n",
              "18        5.998826               2          5.0  257376075.0   \n",
              "11        0.588511               2          5.0  404031556.0   \n",
              "\n",
              "                                          User_Review  \\\n",
              "13  Video h√¨nh ·∫£nh mang t√≠nh ch·∫•t nh·∫≠n xu ·∫°. \\nSho...   \n",
              "16  Jsjsnsjdjkd h√¨nh ·∫£nh minh h·ªça ,mang tc nh·∫≠n xu...   \n",
              "8   H∆∞∆°ng v·ªã:nzndjdjdkd nh∆∞ c·ª•c ƒë·∫•t\\n\\nƒênndnkkwlwk...   \n",
              "18  ƒê·∫≠m v·ªã qu√° ngon ch·∫•t l∆∞·ª£ng gi√° h·ª£p l√Ω ship h√†n...   \n",
              "11  S·∫£n ph·∫£mmmmm\\nM\\nM\\nMm\\nMm\\nMok\\nOkkkkkkkkkkkk...   \n",
              "\n",
              "                                                  URL  Cosine_similarity  \n",
              "13  https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...           0.895438  \n",
              "16  https://shopee.vn/Qu%E1%BA%A3-d%C3%A2u-t%C3%A2...           0.838509  \n",
              "8   https://shopee.vn/100GR-B%C3%B2-kh%C3%B4-x%C3%...           0.826895  \n",
              "18  https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...           0.823328  \n",
              "11  https://shopee.vn/-H%C3%80-N%E1%BB%98I-X%C3%BA...           0.819496  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29020bef-672d-4cd5-a09a-c8c0f13919a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Shop_id</th>\n",
              "      <th>Shop_Name</th>\n",
              "      <th>Prod_id</th>\n",
              "      <th>Prod_Name</th>\n",
              "      <th>Description_Prod</th>\n",
              "      <th>Price</th>\n",
              "      <th>Average_Rating</th>\n",
              "      <th>Total_Comments</th>\n",
              "      <th>User_Rating</th>\n",
              "      <th>User_id</th>\n",
              "      <th>User_Review</th>\n",
              "      <th>URL</th>\n",
              "      <th>Cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>237204869</td>\n",
              "      <td>dacsanphanrangso1</td>\n",
              "      <td>9207719667</td>\n",
              "      <td>500g Ru·ªëc S·∫•y T√¢y Ninh Gi√≤</td>\n",
              "      <td>ru·ªëc s·∫•y kh√¥ li·ªáu ru·ªëc bi·ªÉn t∆∞∆°i s·∫°ch s·∫•y kh√¥ ...</td>\n",
              "      <td>59420.60320</td>\n",
              "      <td>2.311383</td>\n",
              "      <td>29</td>\n",
              "      <td>5.0</td>\n",
              "      <td>64154689.0</td>\n",
              "      <td>Video h√¨nh ·∫£nh mang t√≠nh ch·∫•t nh·∫≠n xu ·∫°. \\nSho...</td>\n",
              "      <td>https://shopee.vn/500g-Ru%E1%BB%91c-S%E1%BA%A5...</td>\n",
              "      <td>0.895438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>42004863</td>\n",
              "      <td>huyenpi.kul</td>\n",
              "      <td>10477233552</td>\n",
              "      <td>Qu·∫£ d√¢u t√¢y s·∫•y d·∫ª</td>\n",
              "      <td>d√¢u_t√¢y s·∫•y d·∫ªo ƒë·∫∑c_s·∫£n cao_c·∫•p dai dai m·ªÅm h∆∞...</td>\n",
              "      <td>29825.88724</td>\n",
              "      <td>2.301471</td>\n",
              "      <td>20</td>\n",
              "      <td>5.0</td>\n",
              "      <td>377287160.0</td>\n",
              "      <td>Jsjsnsjdjkd h√¨nh ·∫£nh minh h·ªça ,mang tc nh·∫≠n xu...</td>\n",
              "      <td>https://shopee.vn/Qu%E1%BA%A3-d%C3%A2u-t%C3%A2...</td>\n",
              "      <td>0.838509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>43086726</td>\n",
              "      <td>TLFood Shop</td>\n",
              "      <td>5806774572</td>\n",
              "      <td>100GR B√≤ kh√¥ x√© s·ª£i th∆°m ngon h√†ng l</td>\n",
              "      <td>gr b√≤ kh√¥ s·ª£i heo gi·∫£ b√≤ m√≥n nh·∫≠u l√Ω_t∆∞·ªüng ƒë·∫•n...</td>\n",
              "      <td>15134.89551</td>\n",
              "      <td>1.939551</td>\n",
              "      <td>2675</td>\n",
              "      <td>5.0</td>\n",
              "      <td>772005828.0</td>\n",
              "      <td>H∆∞∆°ng v·ªã:nzndjdjdkd nh∆∞ c·ª•c ƒë·∫•t\\n\\nƒênndnkkwlwk...</td>\n",
              "      <td>https://shopee.vn/100GR-B%C3%B2-kh%C3%B4-x%C3%...</td>\n",
              "      <td>0.826895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>63406509</td>\n",
              "      <td>ƒê·∫∑c S·∫£n ƒê√† N·∫µng Ch√≠nh G·ªëc</td>\n",
              "      <td>12557561629</td>\n",
              "      <td>100gr CH√Ä B√îNG T√îM/ RU·ªêC T√îM ƒê√Ä N·∫¥NG - si√™u</td>\n",
              "      <td>t√¥m ru·ªëc t√¥m ƒë√† n·∫µng si√™u ngon ƒë·∫∑c_ƒëi·ªÉm s·ª£i ru...</td>\n",
              "      <td>71966.25222</td>\n",
              "      <td>5.998826</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>257376075.0</td>\n",
              "      <td>ƒê·∫≠m v·ªã qu√° ngon ch·∫•t l∆∞·ª£ng gi√° h·ª£p l√Ω ship h√†n...</td>\n",
              "      <td>https://shopee.vn/100gr-CH%C3%80-B%C3%94NG-T%C...</td>\n",
              "      <td>0.823328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2770707</td>\n",
              "      <td>Demacia Station - 39 Th·ª•y Khu√™</td>\n",
              "      <td>9539017473</td>\n",
              "      <td>[H√Ä N·ªòI] X√∫c X√≠ch S·ª•n G√† Cay ƒÇn Li·ªÅn 1 g√≥i 4 v...</td>\n",
              "      <td>x√∫c_x√≠ch s·ª•n non m·ªõi ngon l·∫°_mi·ªáng dai dai c·∫Øn...</td>\n",
              "      <td>9262.24843</td>\n",
              "      <td>0.588511</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>404031556.0</td>\n",
              "      <td>S·∫£n ph·∫£mmmmm\\nM\\nM\\nMm\\nMm\\nMok\\nOkkkkkkkkkkkk...</td>\n",
              "      <td>https://shopee.vn/-H%C3%80-N%E1%BB%98I-X%C3%BA...</td>\n",
              "      <td>0.819496</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29020bef-672d-4cd5-a09a-c8c0f13919a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29020bef-672d-4cd5-a09a-c8c0f13919a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29020bef-672d-4cd5-a09a-c8c0f13919a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}